---
title: "코파일럿 에이전톤 온라인코칭 Q&A : 37"
date: 2025-09-02T00:00:00 KST
categories:
  - 코파일럿에이전톤서울2025
tags:
  - Copilot
  - Agent
excerpt: "copilot Studio 에이전트에서 만든 RAG 에이전트는 답변이 정확하지 않지만, M365 코파일럿에서 에이전트 빌더로 만든 간단한 RAG 챗봇은 답변을 정확하게 하는데 차이점이 무엇인지 궁금합니다."
header:
  overlay_image: assets/images/header/Microsoft365-Copilot-KeyArt-Productivity-6K-01.png
  overlay_filter: 0.5 # same as adding an opacity of 0.5 to a black background
  #caption: "Photo credit: [**Unsplash**](https://unsplash.com)"
  #actions:
  #  - label: "원문보기"
  #    url: "https://techcommunity.microsoft.com/blog/microsoft365copilotblog/what%E2%80%99s-new-in-microsoft-365-copilot--july-2025/4438253"
toc: false
toc_sticky: true
classes: wide
author: 최정우
---

# 💡 에이전톤 Q&A : 37

copilot Studio 에이전트에서 만든 RAG 에이전트는 답변이 정확하지 않지만, M365 코파일럿에서 에이전트 빌더로 만든 간단한 RAG 챗봇은 답변을 정확하게 하는데 차이점이 무엇인지 궁금합니다.
{: .notice--info}

---

# 📝 답변

<iframe width="560" height="315" src="https://www.youtube.com/embed/6CViXcFc4Tc?si=8B0Tk1sLDShtpKGP&amp;start=1862" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

---

사실 이것과 관련하여는 굉장히 할 이야기가 많습니다.

아래 강의의 전반부를 참조해보시면 좋을 것 같습니다.

[에이전트 개발, 어렵다고요? Microsoft랑 하면 쉽습니다! 강의 - 인프런](https://www.inflearn.com/course/%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B0%9C%EB%B0%9C-%EC%96%B4%EB%A0%B5%EB%8B%A4%EA%B3%A0%EC%9A%94-micros)

---

정확한 답변이라는 기준이 사실 여러가지가 있을 수 있겠습니다만,

RAG 챗봇이라는 용어에 익숙하신 것 같으니 그 기준으로 이야기를 해보죠.

우리가 코파일럿/에이전트빌더/코파일럿스튜디오 등으로 RAG 챗봇을 구현할 수 있지만 동작 방식이 조금씩 다릅니다.

- 코파일럿챗 (Web) - 사용자가 개별적으로 파일을 던져주고 물어볼 수 있습니다. 해당 파일의 텍스트를 실시간으로 뽑아서 LLM 프롬프트에 담습니다. 답변이 훌륭합니다. 다만 입력 프롬프트 토큰의 물리적인 제약이 있지요.
- 코파일럿챗 (Work) - 사용자가 개별적으로 파일을 던지거나 선택해서 물어보면 위와 동일. 그런데 그냥 물어보면 현재 사용자의 권한으로 시맨틱 서치를 합니다. 그 시맨틱 서치로 검색된 내용의 청크만 LLM 프롬프트에 담깁니다.

이런 차이가 답변의 스타일과 성향에 결정적인 영향을 줍니다.

- 문서 전체인 100 페이지 분량의 내용을 LLM 에 모두 담아서 질의를 했을 때 - 입력 토큰의 물리적 한계가 있지만 대체로 답변이 충실합니다.
- 검색으로 찾은 문서 일부 분량의 내용을 LLM 에 담아서 질의를 했을 때 - 입력 토큰의 물리적 한계가 없지만, 경우에 따라서 미흡한 답변이 나올 수 있습니다.

따라서 코파일럿이나 에이전트에 참조데이터를 줄 때, 전략적인 판단이 필요합니다.

- 가진 문서가 몇개 안됨 - 쉐어포인트 파일 참조 --> 전문을 LLM 에 보냄
- 가진 문서가 아주 많음 - 쉐어포인트 사이트, 폴더 참조 --> 검색결과 청크를 LLM 에 보냄

이제 코파일럿 스튜디오로 넘어가 보면

- 코파일럿 스튜디오의 쉐어포인트, 원드라이브 참조는 파일이던 사이트이던 모두 검색기반이라고 보시면 됩니다.
- 코파일럿 스튜디오에 파일을 (데이타벌스에) 업로드는 하는 것도 검색기반입니다
- 비교를 해보면 데이터버스에 직접 업로드할 때 품질이 월등히 좋습니다.
